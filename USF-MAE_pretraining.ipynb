{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7dbc18fd-ba70-4e70-bf5a-09ff0be33ee9",
   "metadata": {},
   "source": [
    "# Libraries used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e871be74-b04e-455b-a6a0-55a764636fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision.transforms import (\n",
    "    Compose,\n",
    "    ToTensor,\n",
    "    PILToTensor,\n",
    "    Normalize,\n",
    "    CenterCrop,\n",
    "    RandAugment,\n",
    "    RandomHorizontalFlip,\n",
    "    RandomVerticalFlip,\n",
    "    Resize,\n",
    "    RandomRotation,\n",
    "    RandomResizedCrop,\n",
    "    InterpolationMode\n",
    ")\n",
    "from timm.data.transforms import RandomResizedCropAndInterpolation\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "from mae.models_mae import mae_vit_base_patch16_dec512d8b\n",
    "from US_data_loading import USImagesDataset\n",
    "from PIL import Image, ImageDraw, UnidentifiedImageError\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "from timm.models.vision_transformer import Block\n",
    "from sklearn.model_selection import KFold\n",
    "import random\n",
    "import csv\n",
    "\n",
    "seed = 42\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "np.float = float"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0e3ce18-da94-470a-811e-c523a47d2d03",
   "metadata": {},
   "source": [
    "# Training the USF-MAE model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eca27a1-d867-496b-b275-cd0644dd91fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_learning_rate(epoch, sched_config):\n",
    "    \"\"\"Decay the learning rate with half-cycle cosine after warmup\"\"\"\n",
    "    if epoch < sched_config['warmup_epochs']:\n",
    "        lr = sched_config['max_lr'] * epoch / sched_config['warmup_epochs']\n",
    "    else:\n",
    "        lr = sched_config['min_lr'] + (sched_config['max_lr'] - sched_config['min_lr']) * 0.5 * \\\n",
    "            (1. + math.cos(math.pi * (epoch - sched_config['warmup_epochs']) / (sched_config['total_epochs'] - sched_config['warmup_epochs'])))\n",
    "    return lr\n",
    "\n",
    "def get_lr(optimizer):\n",
    "    for param_group in optimizer.param_groups:\n",
    "        return param_group['max_lr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74053ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_path_parent = \"../US Datasets for USF-MAE Training\"\n",
    "\n",
    "# Recursively get all .png files in all subfolders\n",
    "all_image_paths = glob.glob(os.path.join(images_path_parent, '**', '*.png'), recursive=True)\n",
    "\n",
    "print(f\"Found {len(all_image_paths)} .png images.\")\n",
    "\n",
    "def create_folds(data, n_splits=5):\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=seed)\n",
    "    folds = list(kf.split(data))\n",
    "    return folds\n",
    "\n",
    "folds = create_folds(all_image_paths)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2337413d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_valid_images(image_paths):\n",
    "    valid_paths = []\n",
    "    for path in image_paths:\n",
    "        try:\n",
    "            with Image.open(path) as img:\n",
    "                img.verify()  # Only checks, doesn't decode\n",
    "            valid_paths.append(path)\n",
    "        except (OSError, UnidentifiedImageError, SyntaxError) as e:\n",
    "            print(f\"Skipping corrupted file: {path} â€” {str(e)}\")\n",
    "    return valid_paths\n",
    "\n",
    "all_image_paths = filter_valid_images(all_image_paths)\n",
    "dataset = USImagesDataset(image_paths=all_image_paths)\n",
    "print(f\"Total usable images after filtering: {len(dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1071535c-1829-4f41-b14a-d0b06a5bc987",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "pretrained_weights = torch.load(\"mae_checkpoint/mae_pretrain_vit_base_full.pth\")[\"model\"]\n",
    "\n",
    "save_dir = 'mae_US_saved_models'\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "results = []\n",
    "\n",
    "log_csv_path = os.path.join(save_dir, \"loss_log.csv\")\n",
    "with open(log_csv_path, mode='w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow([\"fold\", \"lr\", \"weight_decay\", \"epochs\", \"final_train_loss\", \"val_loss\"])\n",
    "\n",
    "for fold_idx, (train_idx, val_idx) in enumerate(folds):\n",
    "\n",
    "    print(f\"Training fold {fold_idx+1}/{len(folds)}\")\n",
    "\n",
    "    train_dataset = Subset(USImagesDataset(all_image_paths, do_augmentation=True), train_idx)\n",
    "    val_dataset = Subset(USImagesDataset(all_image_paths, do_augmentation=False), val_idx)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=4)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False, num_workers=4)\n",
    "\n",
    "    for base_learning_rate in [3e-4, 1e-3]:\n",
    "        for weight_decay in [0.01, 0.05]:\n",
    "            for num_epochs in [100]:\n",
    "                learning_rate = base_learning_rate * 128 / 256\n",
    "\n",
    "                model = mae_vit_base_patch16_dec512d8b().cuda()\n",
    "                model.load_state_dict(pretrained_weights)\n",
    "                optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "\n",
    "                # Scheduler configuration\n",
    "                total_epochs = len(train_loader) * num_epochs\n",
    "                warmup_epochs = int(total_epochs * 0.1)\n",
    "                sched_config = {\n",
    "                    \"max_lr\": learning_rate,\n",
    "                    \"min_lr\": 1.0e-5,\n",
    "                    \"total_epochs\": total_epochs,\n",
    "                    \"warmup_epochs\": warmup_epochs,\n",
    "                }\n",
    "\n",
    "                epoch_counter = 0\n",
    "                for epoch in tqdm(range(num_epochs)):\n",
    "                    model.train()\n",
    "                    all_losses = []\n",
    "                    for images in train_loader:\n",
    "                        new_learning_rate = adjust_learning_rate(epoch=epoch_counter, sched_config=sched_config)\n",
    "                        for g in optimizer.param_groups:\n",
    "                            g[\"lr\"] = new_learning_rate\n",
    "                        with torch.cuda.amp.autocast(dtype=torch.bfloat16):\n",
    "                            loss, _, _ = model(images.cuda())\n",
    "\n",
    "                        loss.backward()\n",
    "                        all_losses.append(loss.item())\n",
    "                        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "                        optimizer.step()\n",
    "                        optimizer.zero_grad()\n",
    "                        epoch_counter += 1\n",
    "\n",
    "                    print(f\"Epoch {epoch + 1}/{num_epochs}, Train Loss: {torch.tensor(all_losses).mean().item()}\")\n",
    "\n",
    "                model.eval()\n",
    "                val_losses = []\n",
    "                with torch.no_grad():\n",
    "                    for images in val_loader:\n",
    "                        with torch.cuda.amp.autocast(dtype=torch.bfloat16):\n",
    "                            val_loss, _, _ = model(images.cuda())\n",
    "                        val_losses.append(val_loss.item())\n",
    "\n",
    "                mean_val_loss = torch.tensor(val_losses).mean().item()\n",
    "                print(f\"Val Loss: {mean_val_loss}, Hyperparameters: {base_learning_rate}, {weight_decay}, {num_epochs}\")\n",
    "\n",
    "                model_filename = f\"USF-MAE_fold{fold_idx+1}_lr{base_learning_rate}_wd{weight_decay}_epochs{num_epochs}.pt\"\n",
    "                model_path = os.path.join(save_dir, model_filename)\n",
    "                torch.save(model.state_dict(), model_path)\n",
    "                print(f\"Model saved at: {model_path}\")\n",
    "                \n",
    "                # Log results to CSV\n",
    "                with open(log_csv_path, mode='a', newline='') as file:\n",
    "                    writer = csv.writer(file)\n",
    "                    writer.writerow([\n",
    "                        fold_idx + 1,\n",
    "                        base_learning_rate,\n",
    "                        weight_decay,\n",
    "                        num_epochs,\n",
    "                        round(torch.tensor(all_losses).mean().item(), 6),\n",
    "                        round(mean_val_loss, 6)\n",
    "                    ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78c4ae20",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
